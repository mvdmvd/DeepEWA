{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"/Users/meesvandartel/Desktop/Coursework/CGT/DeepEWA/EWA_imp.jl\")\n",
    "using .EWA, Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Attraction updating function:\n",
    "$$\n",
    "Q_{i}^{\\mu}(t) = \\frac{(1-\\alpha) N(t-1) Q_{i}^{\\mu}(t-1)}{N(t)} + \\frac{\\left[ \\delta + (1-\\delta) \\mathbb{I}(s_i^\\mu,s^{-\\mu}(t)) \\right] \\Pi^\\mu(s_i^\\mu, s^{-\\mu}(t))}{N(t)}\n",
    "$$\n",
    "\n",
    "#### Mixed strategy determination:\n",
    "$$\n",
    "\\sigma^{\\mu}(t)=\\frac{e^{\\beta Q_1^R (t)}}{e^{\\beta Q_1^R (t)} + e^{\\beta Q_2^R (t)}}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Special Cases:\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "&\\text{best response dynamics:  }\\alpha=1, \\quad \\beta = +\\infty, \\quad \\delta = 1, \\quad \\forall \\kappa \\in [0,1] \\\\\n",
    "&\\text{reinforcement learning:  }\\delta = 0, \\quad \\forall \\kappa \\in [0,1] \\\\\n",
    "&\\quad\\text{average RL: } \\quad \\kappa=0, \\quad \\text{cummulative RL: } \\quad \\kappa = 1 \\\\\n",
    "&\\text{ficticious play:  }\\alpha=0, \\quad \\beta = +\\infty, \\quad \\delta = 1, \\quad  \\kappa = 0\\\\\n",
    "&\\quad\\text{stochastic ficticious play:  } \\beta < +\\infty\\\\\n",
    "&\\text{replicator dynamics:  } \\beta \\rightarrow 0, \\quad \\alpha = 0, \\quad \\delta = 1, \\quad \\forall \\kappa \\in (0,1]\\\\\n",
    "&\\text{logit dynamics:  } \\alpha = 1, \\quad \\delta = 1,\\quad \\kappa = 1\n",
    "\\end{aligned}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Q: [[0.0, 0.0], [0.0, 0.0]], prior N: 0.0\n",
      "Iter 1: σ=[[0.5, 0.5], [0.5, 0.5]], s=[2, 1], Q=[[9.0, 3.0], [7.0, 4.0]], N=1.0\n",
      "Iter 2: σ=[[1.0, 0.0], [1.0, 0.0]], s=[1, 1], Q=[[9.0, 3.0], [4.0, 6.0]], N=2.0\n",
      "Iter 3: σ=[[1.0, 0.0], [0.0, 1.0]], s=[1, 2], Q=[[6.666666666666667, 4.333333333333333], [3.0, 6.666666666666667]], N=3.0\n",
      "Iter 4: σ=[[1.0, 0.0], [0.0, 1.0]], s=[1, 2], Q=[[5.5, 5.0], [2.5, 7.0]], N=4.0\n",
      "Iter 5: σ=[[1.0, 0.0], [0.0, 1.0]], s=[1, 2], Q=[[4.8, 5.4], [2.2, 7.2]], N=5.0\n",
      "Iter 6: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[4.333333333333333, 5.666666666666667], [3.0, 6.666666666666667]], N=6.0\n",
      "Iter 7: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[4.0, 5.857142857142857], [3.5714285714285716, 6.285714285714286]], N=7.0\n",
      "Iter 8: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[3.75, 6.0], [4.0, 6.0]], N=8.0\n",
      "Iter 9: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[3.5555555555555554, 6.111111111111111], [4.333333333333333, 5.777777777777778]], N=9.0\n",
      "Iter 10: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[3.4, 6.2], [4.6, 5.6]], N=10.0\n",
      "Iter 500: σ=[[0.0, 1.0], [1.0, 0.0]], s=[2, 1], Q=[[5.023999999999999, 5.271999999999998], [5.296000000000004, 5.136000000000004]], N=500.0\n",
      "Iter 1000: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[4.968000000000002, 5.303999999999995], [5.181999999999994, 5.212000000000003]], N=1000.0\n",
      "Iter 5000: σ=[[1.0, 0.0], [1.0, 0.0]], s=[1, 1], Q=[[5.197600000000006, 5.172800000000002], [5.232400000000008, 5.17839999999999]], N=5000.0\n",
      "Iter 10000: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[5.137399999999996, 5.207200000000014], [5.182000000000001, 5.211999999999988]], N=10000.0\n",
      "Iter 1000000: σ=[[0.0, 1.0], [1.0, 0.0]], s=[2, 1], Q=[[5.181360000000082, 5.1820799999999725], [5.203288000000392, 5.197807999999829]], N=1.0e6\n",
      "_____________________________________________________________________________ß_______________________________________________\n",
      "Q*: [[5.181363818636263, 5.1820778179221545], [5.203289796710595, 5.197806802193027]], N*: 1.000001e6\n",
      "Converged mixed strategy vector: σ =  [[0.0, 1.0], [1.0, 0.0]]\n",
      "Frequencies of player 1: s₁ = 0.299452, s₂ = 0.700548\n",
      "Frequencies of player 2: s₁ = 0.45448, s₂ = 0.54552\n"
     ]
    }
   ],
   "source": [
    "# payoff matrixes\n",
    "coord = [[5 1; 1 4], [5 1; 1 4]]\n",
    "pris = [[5 20; 0 1], [5 20; 0 1]]\n",
    "pennies = [[-1 1; 1 -1], [1 -1; -1 1]]\n",
    "mixed_unique = [[9 2;3 7], [1 7; 8 4]] # The unique mixed NE is [[0.3, 0.7], [0.4, 0.6]] (analytically)\n",
    "\n",
    "params = EWA.init_EWA(\n",
    "Q₀=[[0.0, 0.0], [0.0, 0.0]], N₀=0.0, # priors\n",
    "\n",
    "α=0.0, δ=1.0, κ=0.0, β=Inf64,        # params\n",
    "\n",
    "payoff =    mixed_unique     )       # game\n",
    "Qₜ, Nₜ, sₜ, σₜ, Q_hist, N_hist, s_hist, σ_hist = EWA.run_EWA(params)\n",
    "\n",
    "println(\"_____________________________________________________________________________ß_______________________________________________\")\n",
    "println(\"Q*: $Qₜ, N*: $Nₜ\")\n",
    "println(\"Converged mixed strategy vector: σ =  $σₜ\")\n",
    "\n",
    "p₁ = sum(s[1]==1 for s in s_hist) / length(s_hist)\n",
    "p₂ = 1-p₁\n",
    "println(\"Frequencies of player 1: s₁ = $p₁, s₂ = $p₂\")\n",
    "\n",
    "p₃ = sum(s[2]==1 for s in s_hist) / length(s_hist)\n",
    "p₄ = 1-p₃\n",
    "println(\"Frequencies of player 2: s₁ = $p₃, s₂ = $p₄\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
