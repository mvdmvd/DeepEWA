{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"/Users/meesvandartel/Desktop/Coursework/CGT/DeepEWA/EWA_imp.jl\")\n",
    "using .EWA, Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Attraction updating function:\n",
    "$$\n",
    "Q_{i}^{\\mu}(t) = \\frac{(1-\\alpha) N(t-1) Q_{i}^{\\mu}(t-1)}{N(t)} + \\frac{\\left[ \\delta + (1-\\delta) \\mathbb{I}(s_i^\\mu,s^{-\\mu}(t)) \\right] \\Pi^\\mu(s_i^\\mu, s^{-\\mu}(t))}{N(t)}\n",
    "$$\n",
    "\n",
    "#### Mixed strategy determination:\n",
    "$$\n",
    "\\sigma^{\\mu}(t)=\\frac{e^{\\beta Q_1^R (t)}}{e^{\\beta Q_1^R (t)} + e^{\\beta Q_2^R (t)}}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Special Cases:\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "&\\text{best response dynamics:  }\\alpha=1, \\quad \\beta = +\\infty, \\quad \\delta = 1, \\quad \\forall \\kappa \\in [0,1] \\\\\n",
    "&\\text{reinforcement learning:  }\\delta = 0, \\quad \\forall \\kappa \\in [0,1] \\\\\n",
    "&\\quad\\text{average RL: } \\quad \\kappa=0, \\quad \\text{cummulative RL: } \\quad \\kappa = 1 \\\\\n",
    "&\\text{ficticious play:  }\\alpha=0, \\quad \\beta = +\\infty, \\quad \\delta = 1, \\quad  \\kappa = 0\\\\\n",
    "&\\quad\\text{stochastic ficticious play:  } \\beta < +\\infty\\\\\n",
    "&\\text{replicator dynamics:  } \\beta \\rightarrow 0, \\quad \\alpha = 0, \\quad \\delta = 1, \\quad \\forall \\kappa \\in (0,1]\\\\\n",
    "&\\text{logit dynamics:  } \\alpha = 1, \\quad \\delta = 1,\\quad \\kappa = 1\n",
    "\\end{aligned}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Q: [[0.0, 0.0], [0.0, 0.0]], prior N: 0.0\n",
      "Iter 1: σ=[[0.5, 0.5], [0.5, 0.5]], s=[2, 1], Q=[[9.0, 3.0], [7.0, 4.0]], N=1.0\n",
      "Iter 2: σ=[[1.0, 0.0], [1.0, 0.0]], s=[1, 1], Q=[[9.0, 3.0], [4.0, 6.0]], N=2.0\n",
      "Iter 3: σ=[[1.0, 0.0], [0.0, 1.0]], s=[1, 2], Q=[[6.666666666666667, 4.0], [3.0, 6.666666666666667]], N=3.0\n",
      "Iter 4: σ=[[1.0, 0.0], [0.0, 1.0]], s=[1, 2], Q=[[5.5, 4.5], [2.5, 7.0]], N=4.0\n",
      "Iter 5: σ=[[1.0, 0.0], [0.0, 1.0]], s=[1, 2], Q=[[4.8, 4.8], [2.2, 7.2]], N=5.0\n",
      "Iter 6: σ=[[0.5, 0.5], [0.0, 1.0]], s=[1, 2], Q=[[4.333333333333333, 5.0], [2.0, 7.333333333333333]], N=6.0\n",
      "Iter 7: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[4.0, 5.142857142857143], [2.7142857142857144, 6.857142857142857]], N=7.0\n",
      "Iter 8: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[3.75, 5.25], [3.25, 6.5]], N=8.0\n",
      "Iter 9: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[3.5555555555555554, 5.333333333333333], [3.6666666666666665, 6.222222222222222]], N=9.0\n",
      "Iter 10: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[3.4, 5.4], [4.0, 6.0]], N=10.0\n",
      "Iter 500: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[4.435999999999993, 4.955999999999998], [5.2, 5.200000000000002]], N=500.0\n",
      "Iter 1000: σ=[[0.0, 1.0], [0.0, 1.0]], s=[2, 2], Q=[[4.764999999999993, 4.814999999999995], [5.055999999999998, 5.296000000000002]], N=1000.0\n",
      "Converged at iter: 4119\n",
      "____________________________________________________________________________________________________________________________\n",
      "Q*: [[4.771116504854363, 4.812378640776705], [5.141747572815538, 5.2388349514563135]], N*: 4120.0\n",
      "Game: [[9 2; 3 6], [1 7; 8 4]]\n",
      "Converged mixed strategy vector: σ =  [[0.0, 1.0], [0.0, 1.0]]\n",
      "Frequencies of player 1: s₁ = 0.30985915492957744, s₂ = 0.6901408450704225\n",
      "Frequencies of player 2: s₁ = 0.3958232151529869, s₂ = 0.6041767848470131\n"
     ]
    }
   ],
   "source": [
    "# payoff matrixes\n",
    "coord = [[5 1; 1 4], [5 1; 1 4]]\n",
    "pris = [[5 0; 20 1], [5 0; 20 1]]\n",
    "pennies = [[-1 1; 1 -1], [1 -1; -1 1]]\n",
    "cyclic = [[5 1;1 4],[-5 1; 1 -4]]\n",
    "mixed = [[9 2;3 6], [1 7; 8 4]] # The unique mixed NE is [[0.3, 0.7], [0.4, 0.6]] (analytically)\n",
    "mixed_2 = [[2 1;1 4],[-3 1; 2 -1]] # mixed NE is 2/7, 5/7; 3/4, 1/4 analytically\n",
    "\n",
    "payoff = mixed # game\n",
    "params = EWA.init_EWA(\n",
    "Q₀=[[0.0, 0.0], [0.0, 0.0]], N₀=0.0, # priors\n",
    "α=0.0, δ=1.0, κ=0.0, β=Inf64, # params\n",
    "\n",
    "payoff=payoff)       \n",
    "Qₜ, Nₜ, sₜ, σₜ, freq_1, freq_2 = EWA.run_EWA(params)\n",
    "\n",
    "println(\"____________________________________________________________________________________________________________________________\")\n",
    "println(\"Q*: $Qₜ, N*: $Nₜ\")\n",
    "println(\"Game: $payoff\")\n",
    "println(\"Converged mixed strategy vector: σ =  $σₜ\")\n",
    "\n",
    "p₂ = 1-freq_1\n",
    "println(\"Frequencies of player 1: s₁ = $freq_1, s₂ = $p₂\")\n",
    "\n",
    "p₄ = 1-freq_2\n",
    "println(\"Frequencies of player 2: s₁ = $freq_2, s₂ = $p₄\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
