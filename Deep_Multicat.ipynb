{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "include(\"/Users/meesvandartel/Desktop/Coursework/CGT/DeepEWA/FastEWA.jl\")\n",
        "using Flux, .fEWA, Random, IterTools, ProgressMeter, DataFrames, CSV, Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this data will be for this specific coordination game with 2 NE and 1 mixed NE.\n",
        "coord = [[[5 1; 1 4], [5 1; 1 4]], fEWA.find_NE_mixed([[5 1; 1 4], [5 1; 1 4]])]\n",
        "dom = [[[5 0; 20 1], [5 0; 20 1]], fEWA.find_NE_mixed([[5 0; 20 1], [5 0; 20 1]])]\n",
        "cyclic = [[[5 1;1 4],[-5 1; 1 -4]], fEWA.find_NE_mixed([[5 1;1 4],[-5 1; 1 -4]])]\n",
        "\n",
        "game = coord\n",
        "points = 10000 \n",
        "\n",
        "α_grid = rand(0.0:0.0001:1.0, points) \n",
        "κ_grid = rand(0.0:0.0001:1.0, points)\n",
        "δ_grid = rand(0.0:0.0001:1.0, points)\n",
        "β_grid = exp.(rand(0.0:0.001:2.5, points)) # take exp to get the lim to infty effect since β is unbounded above\n",
        " combs = [[α_grid[i], κ_grid[i], δ_grid[i], β_grid[i]] for i in 1:points]\n",
        "\n",
        "#testing\n",
        "#combs = [[0.0, 1.0, δ_grid[i], β_grid[i]] for i in 1:points]\n",
        "\n",
        "subset=Int64(floor(0.6*length(combs))) #60/40 train test split, since we have many obs\n",
        "\n",
        "x_train, x_test = combs[1:subset], combs[(subset+1):end]\n",
        "y_train, y_test = Vector{Vector{Bool}}(undef, length(x_train)), Vector{Vector{Bool}}(undef, length(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# should take about 6min for 1mil obs\n",
        "@showprogress for i in 1:length(x_train)\n",
        "    comb=x_train[i]\n",
        "    α, κ, δ, β = comb\n",
        "    params = fEWA.init_EWA(;α=α, κ=κ, δ=δ, β=β,game=game)\n",
        "    sₜ, σ, Qₜ, cycles, pure_NE, mixed_NE, FP  = fEWA.multicat_FastEWA(params)\n",
        "    y_train[i] = [cycles, pure_NE, mixed_NE, FP]\n",
        "end\n",
        "\n",
        "@showprogress for i in 1:length(x_test)\n",
        "    comb = x_test[i]\n",
        "    α, κ, δ, β = comb\n",
        "    params = fEWA.init_EWA(;α=α, κ=κ, δ=δ, β=β,game=game)\n",
        "    sₜ, σ, Qₜ, cycles, pure_NE, mixed_NE, FP = fEWA.multicat_FastEWA(params)\n",
        "    y_test[i] = [cycles, pure_NE, mixed_NE, FP]\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = hcat([Float32.(x[1:4]) for x in x_train]...)\n",
        "y_train = hcat([Float32.(x[1:4]) for x in y_train]...)\n",
        "\n",
        "DeepEWA= Chain(\n",
        "    Dense(4 => 32, relu),\n",
        "    Dense(32 => 32, relu),\n",
        "    Dense(32 => 4))\n",
        "\n",
        "out1 = DeepEWA(x_train)\n",
        "probs1 = softmax(out1)\n",
        "\n",
        "\n",
        "target = Flux.onehotbatch(y_train, 1:4)\n",
        "loader = Flux.DataLoader((x_train, target), batchsize=64, shuffle=true);\n",
        "\n",
        "opt_state = Flux.setup(Flux.AdaGrad(), DeepEWA)\n",
        "\n",
        "losses=[]\n",
        "@showprogress for epoch in 1:2000\n",
        "    for xy in loader\n",
        "        x,y = xy\n",
        "        loss, grads = Flux.withgradient(DeepEWA) do m\n",
        "            y_hat = m(x)\n",
        "            Flux.logitcrossentropy(y_hat, y)\n",
        "        end\n",
        "        Flux.update!(opt_state, DeepEWA, grads[1])\n",
        "        push!(losses, loss)\n",
        "    end\n",
        "end\n",
        "\n",
        "opt_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_test = hcat([Float32.(x[1:4]) for x in x_test]...)\n",
        "y_test = hcat([Float32.(x[1:4]) for x in y_test]...)\n",
        "\n",
        "\n",
        "out2 = DeepEWA(x_test)\n",
        "probs2 = softmax(out2)\n",
        "mean((probs2[1,:].>0.5).==y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "using Plots  # to draw the above figure\n",
        "\n",
        "p_true = scatter(x_test[3,:], x_test[4,:], zcolor=y_train, title=\"True classification\", legend=false)\n",
        "p_done = scatter(x_test[3,:], x_test[4,:], zcolor=probs2[1,:], title=\"Trained network\", legend=false)\n",
        "\n",
        "plot(p_true, p_done, layout=(1,2), size=(1000,330))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#=\n",
        "plot(losses; xaxis=(:log10, \"iteration\"),\n",
        "    yaxis=\"loss\", label=\"per batch\")\n",
        "n = length(loader)\n",
        "plot!(n:n:length(losses), mean.(Iterators.partition(losses, n)),\n",
        "    label=\"epoch mean\", dpi=200)\n",
        "    =#\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Julia 1.11.4",
      "language": "julia",
      "name": "julia-1.11"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
